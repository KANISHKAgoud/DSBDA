{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f92b92-aa67-47ed-a3cb-1b23d962f46b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed74b75f-fd25-4fc3-8915-95684d7bcd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Accuracy: 1.00\n",
      "Error Rate: 0.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "file_path = r\"C:\\Users\\comp\\Documents\\DSBDA PRACTICALS\\DSBDA\\6th_practical\\iris.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Dataset Preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 2: Split features and labels\n",
    "X = df.iloc[:, :-1]  # all columns except the last one\n",
    "y = df.iloc[:, -1]   # last column (species)\n",
    "\n",
    "# Step 3: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Train Naïve Bayes model\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 6: Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=y.unique())\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Extracting TP, FP, FN, TN from confusion matrix\n",
    "# This works for binary classification; for multiclass, we compute metrics per class.\n",
    "# So we’ll just calculate metrics directly using sklearn:\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')  # 'macro' for multi-class\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "error_rate = 1 - accuracy\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}\")\n",
    "print(f\"Error Rate: {error_rate:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d796fc0-cb0f-415c-bc24-0d23d7002398",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
